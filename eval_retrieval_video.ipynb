{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cell\n",
    "'''\n",
    " * Copyright (c) 2022, salesforce.com, inc.\n",
    " * All rights reserved.\n",
    " * SPDX-License-Identifier: BSD-3-Clause\n",
    " * For full license text, see LICENSE.txt file in the repo root or https://opensource.org/licenses/BSD-3-Clause\n",
    " * By Junnan Li\n",
    "'''\n",
    "import argparse\n",
    "import os\n",
    "import ruamel_yaml as yaml\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from models.blip_retrieval import blip_retrieval\n",
    "import utils\n",
    "from data.video_dataset import VideoDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "@torch.no_grad()\n",
    "def evaluation(model, data_loader, tokenizer, device, config):\n",
    "    # test\n",
    "    model.eval() \n",
    "    \n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    header = 'Evaluation:'    \n",
    "    \n",
    "    print('Computing features for evaluation...')\n",
    "    start_time = time.time()  \n",
    "\n",
    "    texts = data_loader.dataset.text   \n",
    "    num_text = len(texts)\n",
    "    text_bs = 256\n",
    "    text_ids = []\n",
    "    text_embeds = []  \n",
    "    text_atts = []\n",
    "    for i in range(0, num_text, text_bs):\n",
    "        text = texts[i: min(num_text, i+text_bs)]\n",
    "        text_input = tokenizer(text, padding='max_length', truncation=True, max_length=35, return_tensors=\"pt\").to(device) \n",
    "        text_output = model.text_encoder(text_input.input_ids, attention_mask = text_input.attention_mask, mode='text')  \n",
    "        text_embed = F.normalize(model.text_proj(text_output.last_hidden_state[:,0,:]))\n",
    "        text_embeds.append(text_embed)   \n",
    "        text_ids.append(text_input.input_ids)\n",
    "        text_atts.append(text_input.attention_mask)\n",
    "    \n",
    "    text_embeds = torch.cat(text_embeds,dim=0)\n",
    "    text_ids = torch.cat(text_ids,dim=0)\n",
    "    text_atts = torch.cat(text_atts,dim=0)\n",
    "    text_ids[:,0] = tokenizer.additional_special_tokens_ids[0]\n",
    "    \n",
    "    video_feats = []\n",
    "    video_embeds = []\n",
    "    for video, video_id in data_loader: \n",
    "\n",
    "        B,N,C,W,H = video.size()\n",
    "        video = video.view(-1,C,W,H)\n",
    "        video = video.to(device,non_blocking=True) \n",
    "        video_feat = model.visual_encoder(video)        \n",
    "        video_embed = model.vision_proj(video_feat[:,0,:])   \n",
    "        video_embed = video_embed.view(B,N,-1).mean(dim=1)\n",
    "        video_embed = F.normalize(video_embed,dim=-1)  \n",
    "       \n",
    "        video_feat = video_feat.view(B,-1,video_feat.shape[-1])\n",
    "        video_feats.append(video_feat.cpu())\n",
    "        video_embeds.append(video_embed)\n",
    "     \n",
    "    video_feats = torch.cat(video_feats,dim=0)\n",
    "    video_embeds = torch.cat(video_embeds,dim=0)\n",
    "    \n",
    "    sims_matrix = video_embeds @ text_embeds.t()\n",
    "    score_matrix_v2t = torch.full((len(texts),len(texts)),-100.0).to(device) \n",
    "    \n",
    "    num_tasks = utils.get_world_size()\n",
    "    rank = utils.get_rank() \n",
    "    step = sims_matrix.size(0)//num_tasks + 1\n",
    "    start = rank*step\n",
    "    end = min(sims_matrix.size(0),start+step)\n",
    "\n",
    "    for i,sims in enumerate(metric_logger.log_every(sims_matrix[start:end], 50, header)): \n",
    "        topk_sim, topk_idx = sims.topk(k=config['k_test'], dim=0)\n",
    "        \n",
    "        encoder_output = video_feats[start+i].repeat(config['k_test'],1,1).to(device,non_blocking=True) \n",
    "        encoder_att = torch.ones(encoder_output.size()[:-1],dtype=torch.long).to(device,non_blocking=True) \n",
    "        output = model.text_encoder(text_ids[topk_idx], \n",
    "                                    attention_mask = text_atts[topk_idx],\n",
    "                                    encoder_hidden_states = encoder_output,\n",
    "                                    encoder_attention_mask = encoder_att,                             \n",
    "                                    return_dict = True,\n",
    "                                   )\n",
    "        score = model.itm_head(output.last_hidden_state[:,0,:])[:,1]\n",
    "        score_matrix_v2t[start+i,topk_idx] = score + topk_sim\n",
    "        \n",
    "    sims_matrix = sims_matrix.t()\n",
    "    score_matrix_t2v = torch.full((len(texts),len(texts)),-100.0).to(device) \n",
    "    \n",
    "    step = sims_matrix.size(0)//num_tasks + 1\n",
    "    start = rank*step\n",
    "    end = min(sims_matrix.size(0),start+step)    \n",
    "    \n",
    "    for i,sims in enumerate(metric_logger.log_every(sims_matrix[start:end], 50, header)): \n",
    "        \n",
    "        topk_sim, topk_idx = sims.topk(k=config['k_test'], dim=0)\n",
    "        encoder_output = video_feats[topk_idx].to(device,non_blocking=True) \n",
    "        encoder_att = torch.ones(encoder_output.size()[:-1],dtype=torch.long).to(device,non_blocking=True) \n",
    "        output = model.text_encoder(text_ids[start+i].repeat(config['k_test'],1), \n",
    "                                    attention_mask = text_atts[start+i].repeat(config['k_test'],1),\n",
    "                                    encoder_hidden_states = encoder_output,\n",
    "                                    encoder_attention_mask = encoder_att,                             \n",
    "                                    return_dict = True,\n",
    "                                   )\n",
    "        score = model.itm_head(output.last_hidden_state[:,0,:])[:,1]\n",
    "        score_matrix_t2v[start+i,topk_idx] = score + topk_sim\n",
    "\n",
    "    if args.distributed:\n",
    "        dist.barrier()   \n",
    "        torch.distributed.all_reduce(score_matrix_v2t, op=torch.distributed.ReduceOp.SUM) \n",
    "        torch.distributed.all_reduce(score_matrix_t2v, op=torch.distributed.ReduceOp.SUM)        \n",
    "        \n",
    "    total_time = time.time() - start_time\n",
    "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "    print('Evaluation time {}'.format(total_time_str)) \n",
    "\n",
    "    return score_matrix_v2t.cpu().numpy(), score_matrix_t2v.cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "# Metric calculation function            \n",
    "@torch.no_grad()\n",
    "def itm_eval(scores_v2t, scores_t2v, txt2vmg, vid2txt):\n",
    "    \n",
    "    #Video->Text \n",
    "    ranks = np.zeros(scores_v2t.shape[0])\n",
    "    for index,score in enumerate(scores_v2t):\n",
    "        inds = np.argsort(score)[::-1]\n",
    "        ranks[index] = np.where(inds == vid2txt[index])[0][0]\n",
    "\n",
    "    # Compute metrics\n",
    "    tr1 = 100.0 * len(np.where(ranks < 1)[0]) / len(ranks)\n",
    "    tr5 = 100.0 * len(np.where(ranks < 5)[0]) / len(ranks)\n",
    "    tr10 = 100.0 * len(np.where(ranks < 10)[0]) / len(ranks)\n",
    "  \n",
    "    #Text->Video \n",
    "    ranks = np.zeros(scores_t2v.shape[0])\n",
    "    \n",
    "    for index,score in enumerate(scores_t2v):\n",
    "        inds = np.argsort(score)[::-1]\n",
    "        ranks[index] = np.where(inds == txt2vmg[index])[0][0]\n",
    "    \n",
    "    mdR = np.median(ranks+1)\n",
    "        \n",
    "    # Compute metrics\n",
    "    vr1 = 100.0 * len(np.where(ranks < 1)[0]) / len(ranks)\n",
    "    vr5 = 100.0 * len(np.where(ranks < 5)[0]) / len(ranks)\n",
    "    vr10 = 100.0 * len(np.where(ranks < 10)[0]) / len(ranks)        \n",
    "\n",
    "    tr_mean = (tr1 + tr5 + tr10) / 3\n",
    "    vr_mean = (vr1 + vr5 + vr10) / 3\n",
    "    r_mean = (tr_mean + vr_mean) / 2\n",
    "\n",
    "    eval_result =  {'txt_r1': tr1,\n",
    "                    'txt_r5': tr5,\n",
    "                    'txt_r10': tr10,\n",
    "                    'txt_r_mean': tr_mean,\n",
    "                    'vid_r1': vr1,\n",
    "                    'vid_r5': vr5,\n",
    "                    'vid_r10': vr10,\n",
    "                    'vid_r_mean': vr_mean,\n",
    "                    'vid_mdR': mdR,\n",
    "                    'r_mean': r_mean}\n",
    "    return eval_result\n",
    "\n",
    "\n",
    "\n",
    "# Main execution\n",
    "def main(args, config):\n",
    "    utils.init_distributed_mode(args)    \n",
    "    \n",
    "    device = torch.device(args.device)\n",
    "\n",
    "    # fix the seed for reproducibility\n",
    "    seed = args.seed + utils.get_rank()\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    #### Dataset #### \n",
    "    print(\"Creating retrieval dataset\")\n",
    "    test_dataset = VideoDataset(config['video_root'],config['ann_root'],num_frm=config['num_frm_test'],\n",
    "                                max_img_size=config['image_size'], frm_sampling_strategy='uniform')\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        shuffle=False,\n",
    "    )  \n",
    "\n",
    "    #### Model #### \n",
    "    print(\"Creating model\")\n",
    "    model = blip_retrieval(pretrained=config['pretrained'], image_size=config['image_size'], vit=config['vit'])\n",
    "    \n",
    "    model = model.to(device)   \n",
    "    \n",
    "    model_without_ddp = model\n",
    "    if args.distributed:\n",
    "        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])\n",
    "        model_without_ddp = model.module   \n",
    "    \n",
    "    score_v2t, score_t2v, = evaluation(model_without_ddp, test_loader, model_without_ddp.tokenizer, device, config)\n",
    "\n",
    "    if utils.is_main_process():  \n",
    "\n",
    "        test_result = itm_eval(score_v2t, score_t2v, test_loader.dataset.txt2video, test_loader.dataset.video2txt)  \n",
    "        print(test_result)\n",
    "\n",
    "        log_stats = {**{f'{k}': v for k, v in test_result.items()},}\n",
    "        with open(os.path.join(args.output_dir, \"test_result.txt\"),\"a\") as f:\n",
    "            f.write(json.dumps(log_stats) + \"\\n\")     \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration cell - replace argparse\n",
    "config_path = './configs/retrieval_msrvtt.yaml'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.Loader)\n",
    "\n",
    "# Define args as a simple namespace object\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.config = config_path\n",
    "        self.output_dir = 'output/Retrieval_msrvtt'\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.seed = 42\n",
    "        self.world_size = 1\n",
    "        self.dist_url = 'env://'\n",
    "        self.distributed = False  # Changed to False for notebook usage\n",
    "        self.gpu = 0\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# Create output directory\n",
    "Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "yaml.dump(config, open(os.path.join(args.output_dir, 'config.yaml'), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "if __name__ == '__main__':\n",
    "    main(args, config)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
